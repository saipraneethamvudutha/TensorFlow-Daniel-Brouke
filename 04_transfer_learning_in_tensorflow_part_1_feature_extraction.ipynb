{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad962559",
   "metadata": {},
   "source": [
    "# Transfer Learning with tensorflow Part 1: Feature Extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's architecture and learned patterns for our own problem.\n",
    "1. Can leverage an existing neural network architecture proven to work on problems similar to our own. \n",
    "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own,then we can adapt those patterns to our own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062215b2",
   "metadata": {},
   "source": [
    "## Downloading and becoming one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22318a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data(10% of 10 food classes from Food101)\n",
    "import zipfile\n",
    "\n",
    "# Unzip the downloaded file\n",
    "zip_ref=zipfile.ZipFile(\"10_food_classes_10_percent.zip\",\"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c21c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent\\test'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\chicken_curry'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\chicken_wings'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\fried_rice'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\grilled_salmon'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\hamburger'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\ice_cream'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\pizza'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\ramen'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\steak'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\sushi'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent\\train'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\chicken_curry'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\chicken_wings'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\fried_rice'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\grilled_salmon'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\hamburger'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\ice_cream'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\pizza'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\ramen'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\steak'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\sushi'.\n"
     ]
    }
   ],
   "source": [
    "# How many images in each folder?\n",
    "import os\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files \n",
    "for dirpath,dirnames,filesnames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filesnames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f4cf6",
   "metadata": {},
   "source": [
    "## Creating data loaders(preparing the data)\n",
    "\n",
    "We'll use the `ImageDataGenerator` class to load in our images in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74921f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images\n",
      "Found 750 images belonging to 10 classes.\n",
      "Testing images\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setup data inputs\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_dir=\"10_food_classes_10_percent/train/\"\n",
    "test_dir=\"10_food_classes_10_percent/test/\"\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1/225.)\n",
    "test_datagen=ImageDataGenerator(rescale=1/225.)\n",
    "\n",
    "print(\"Training Images\")\n",
    "train_data_10_percent=train_datagen.flow_from_directory(train_dir,\n",
    "                                                        target_size=IMAGE_SHAPE,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        class_mode=\"categorical\")\n",
    "print(\"Testing images\")\n",
    "test_data_10_percent=test_datagen.flow_from_directory(test_dir,\n",
    "                                                      target_size=IMAGE_SHAPE,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9a415",
   "metadata": {},
   "source": [
    "## Setting up callbacks(things to run whilst our model trains)\n",
    "\n",
    "Callbacks are extra functionality you can add to your models to be performed during or after training.Some of the modet popular callbacks:\n",
    "\n",
    "* Tracking experiments with the TensorBoard callback\n",
    "* Model checkpoint with the ModelCheckpoint callback\n",
    "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056620ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb317e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorboard callback (functionized beacuse we need to create a new one for each model)\n",
    "import datetime\n",
    "\n",
    "def create_tensorborad_callback(dir_name,experiment_name):\n",
    "    log_dir=dir_name+\"/\"+experiment_name+\"/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    print(f\"Saving TensorBoard log files to :{log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a0e04",
   "metadata": {},
   "source": [
    "## Creating models using Tensorflow Hub\n",
    "\n",
    "In the past we've used tensorflow to create our models layer by layers from scratch.\n",
    "\n",
    "Now we'regoing to do a similar process,except the majority of our model's layers are going to come from tensorflow Hub.\n",
    "We can access pretrained models on: [Kaggle is now TensorFlow Hub](https://www.tensorflow.org/hub)\n",
    "\n",
    "Browsing the **TensorFlow Hub(NOW KAGGLE)** and sorting for image classification ,we found the follwoing feature vector model link :  https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15116758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the follwoing two models\n",
    "resnet_url = \"https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\"\n",
    "\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a92422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceffd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a create_model() function to create a model from a URL\n",
    "def create_model(model_url,num_classes=10):\n",
    "    \"\"\"\n",
    "    Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
    "    \n",
    "    Args:\n",
    "    model_url(str):A TensorFlow Hub feature extraction URL.\n",
    "    num_classes(int): Number of output neurons in the output layer,\n",
    "    should be equal to number of target classes,default 10.\n",
    "\n",
    "    Returns:\n",
    "    An uncompiled Keras Sequential model with model_url as feature extractor layer and Dense output\n",
    "    layer with num_classes output neurons.\n",
    "    \"\"\"\n",
    "    # Download the pretrained model and save it as Keras layer\n",
    "    feature_extractor_layer=hub.KerasLayer(model_url,\n",
    "                                           trainable=False,\n",
    "                                           name=\"feature_extractions_layer\",\n",
    "                                            input_shape=IMAGE_SHAPE+(3,)) # freeze already learned patterns\n",
    "    # Create our model\n",
    "    model=tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.Dense(num_classes,activation=\"softmax\",name=\"output_layer\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842d862",
   "metadata": {},
   "source": [
    "### Creating and testing ResNet Tensorflow Hub Feature Extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f6bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet model\n",
    "resnet_model=create_model(resnet_url,num_classes=train_data_10_percent.num_classes)\n",
    "\n",
    "# Compile \n",
    "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28e63e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_extractions_layer (  (None, 2048)             23561152  \n",
      " KerasLayer)                                                     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,581,642\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,561,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6774ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to :tensorflow_hub/resnet50v2/20250530-001535\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 17s 507ms/step - loss: 1.9805 - accuracy: 0.3213 - val_loss: 1.1269 - val_accuracy: 0.6332\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 11s 450ms/step - loss: 0.8591 - accuracy: 0.7347 - val_loss: 0.8023 - val_accuracy: 0.7480\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 11s 450ms/step - loss: 0.5576 - accuracy: 0.8413 - val_loss: 0.6983 - val_accuracy: 0.7752\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 11s 451ms/step - loss: 0.4580 - accuracy: 0.8760 - val_loss: 0.5896 - val_accuracy: 0.8104\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 10s 448ms/step - loss: 0.3357 - accuracy: 0.9213 - val_loss: 0.5976 - val_accuracy: 0.8012\n"
     ]
    }
   ],
   "source": [
    "# Let's fit our ResNet model to the data(10 percent of 10 classes)\n",
    "resnet_history=resnet_model.fit(train_data_10_percent\n",
    "                                ,epochs=5,\n",
    "                                steps_per_epoch=len(train_data_10_percent),\n",
    "                                validation_data=test_data_10_percent,\n",
    "                                callbacks=[create_tensorborad_callback(dir_name=\"tensorflow_hub\",\n",
    "                                                                       experiment_name=\"resnet50v2\")],\n",
    "                                validation_steps=len(test_data_10_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa972e0",
   "metadata": {},
   "source": [
    "Wow!!!\n",
    "\n",
    "That is Incredible Our transfer learning feature extractor model out performed ALL of the previous models we built by hand..(substantially) and in a quicker training time AND with only 10 % of the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a484df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to plot our loss curves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfamd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
